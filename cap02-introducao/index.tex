\section{Introduction}

O volume de dados disponível cresce de forma acelerada na internet desde o seu “boom”, impulsionado por redes sociais, comércio eletrônico, artigos, bibliotecas de vídeos e imagens, entre outras plataformas digitais. Presume-se que, em 2025, o mundo atingirá um marco de 181 zettabytes de dados gerados \cite{explodingtopics2025}, o que demonstra o desafio de coletar, processar e transformar essa quantidade enorme de informações em conhecimento útil para os setores público e privado. Dessa forma, torna-se cada vez mais necessária a utilização de técnicas que automatizem a extração dessas informações, capazes de lidar com dados em larga escala.

O \textit{web scraping} é uma técnica que permite a coleta automática de dados da Web, realizando a conversão de páginas em informações estruturadas que podem ser analisadas em diferentes contextos, de acordo com o propósito final \cite{lotfi2022}. Quando utilizado em conjunto com a Inteligência Artificial (IA), especialmente em modelos de linguagem de grande porte (LLMs), permite não apenas a extração, mas também análises avançadas, contextualização e suporte às tomadas de decisão.

Este artigo tem como objetivo analisar os conceitos de \textit{web scraping} e sua relação com a IA, destacando suas aplicações práticas, evolução histórica, estágio comercial e perspectivas futuras. Além disso, são discutidos os aspectos legais e éticos relacionados ao uso dessas técnicas, considerando regulamentações locais, como a Lei Geral de Proteção de Dados (LGPD).

Com esse propósito, o artigo está organizado da seguinte maneira: após esta introdução, apresenta-se uma revisão teórica sobre \textit{web scraping}, Inteligência Artificial e sua integração em pipelines de Extract--Transform--Load (ETL), bem como em arquiteturas de \textit{retrieval-augmented generation} (RAG). Em seguida, abordam-se aplicações práticas nos diferentes níveis organizacionais. Por fim, apresentam-se as considerações finais e as referências utilizadas.